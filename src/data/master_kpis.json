[
  {
    "KPI Name":"Color Contrast Compliance",
    "Benchmark":"According to WCAG (industry standard used to enforce international accessibility laws), the visual presentation of text and images of text must follow contrast ratios of 4.5:1 for normal text and 3:1 for large text.",
    "Definition":"Meets accessibility standards for text contrast.",
    "Goal":"Ensure all text and UI elements meet WCAG AA\/AAA contrast ratios to improve accessibility for visually impaired users.",
    "Category":"Accessibility",
    "Metric Type":"Quantitative",
    "Design Stage":"Prototyping",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Website, Marketing Site",
    "More Info":"https:\/\/webaim.org\/articles\/contrast\/"
  },
  {
    "KPI Name":"Keyboard Navigation Support",
    "Benchmark":"All interactive elements must be operable via Tab, Shift+Tab, and Enter with no keyboard traps, per WCAG 2.1 AA compliance.",
    "Definition":"Usable entirely via keyboard shortcuts.",
    "Goal":"Enable full keyboard navigation throughout the interface to support users who rely on assistive technologies.",
    "Category":"Accessibility",
    "Metric Type":"Quantitative",
    "Design Stage":"Prototyping",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Admin Tool",
    "More Info":"https:\/\/webaim.org\/techniques\/keyboard\/"
  },
  {
    "KPI Name":"Screen Reader Compatibility",
    "Benchmark":"Should support JAWS, NVDA, and VoiceOver screen readers without critical issues; all semantic HTML elements must be labeled correctly.",
    "Definition":"Supports screen readers for accessibility.",
    "Goal":"Ensure compatibility with popular screen readers to allow visually impaired users to fully navigate and interact.",
    "Category":"Accessibility",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Web App, Kiosk",
    "More Info":"https:\/\/webaim.org\/techniques\/screenreader\/"
  },
  {
    "KPI Name":"Bounce Rate",
    "Benchmark":"Bounce rate should be under 40% for B2C and 30% for B2B landing pages, per analytics benchmarks from Google and Hotjar.",
    "Definition":"Percentage of users who leave after one page.",
    "Goal":"Reduce bounce rate by improving first-impression content, page load speed, and alignment with user intent.",
    "Category":"Behavioral",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Awareness",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Landing Page, Website",
    "More Info":"https:\/\/mailchimp.com\/resources\/decrease-bounce-rate\/"
  },
  {
    "KPI Name":"Conversion Funnel Drop-off",
    "Benchmark":"Less than 30% drop-off between funnel steps is ideal; optimize form clarity, button hierarchy, and trust indicators to reduce abandonment.",
    "Definition":"Users exiting before completing desired steps.",
    "Goal":"Identify and optimize steps in the conversion funnel where users are dropping off to increase completed conversions.",
    "Category":"Behavioral",
    "Metric Type":"Composite",
    "Design Stage":"Validation",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"E-commerce, Funnel",
    "More Info":"https:\/\/contentsquare.com\/blog\/funnel-drop-off-rate\/"
  },
  {
    "KPI Name":"Form Abandonment Rate",
    "Benchmark":"Form abandonment rate under 60% on desktop and 70% on mobile is expected; clear labels, progress indicators, and autofill boost completion.",
    "Definition":"Forms started but not submitted.",
    "Goal":"Reduce the percentage of users who abandon forms by simplifying fields and improving guidance.",
    "Category":"Behavioral",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Forms, Signups",
    "More Info":"https:\/\/contentsnare.com\/form-abandonment\/"
  },
  {
    "KPI Name":"Task Abandonment Rate",
    "Benchmark":"Task abandonment should stay below 15% for essential flows; measured through task analysis and usability test session tracking.",
    "Definition":"Tasks users started but didn't complete.",
    "Goal":"Minimize the number of users who begin but do not complete key tasks by clarifying steps and expectations.",
    "Category":"Behavioral",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Onboarding, Signup Flows",
    "More Info":"https:\/\/www.indeed.com\/career-advice\/career-development\/what-is-abandonment-rate"
  },
  {
    "KPI Name":"Heatmap Click Rate",
    "Benchmark":"Top 25% of clicks should fall on intended CTA or content; heatmaps should show clear, clustered intent per Nielsen Norman heuristics.",
    "Definition":"Where and how often users click.",
    "Goal":"Increase click density on high-priority areas by improving visual hierarchy and CTAs.",
    "Category":"Behavioral",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Web App, Website",
    "More Info":"https:\/\/vwo.com\/website-heatmap\/click-heatmaps\/"
  },
  {
    "KPI Name":"Readability Score",
    "Benchmark":"Flesch-Kincaid reading ease should score above 60, targeting an 8th-grade level or below to meet broad accessibility and comprehension standards.",
    "Definition":"Ease of reading based on standard formulas.",
    "Goal":"Maintain high readability scores to ensure users can easily digest content across different education levels.",
    "Category":"Content",
    "Metric Type":"Quantitative",
    "Design Stage":"Prototyping",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Documentation Site, Knowledge Base",
    "More Info":"https:\/\/readable.com\/readability\/what-is-readability\/"
  },
  {
    "KPI Name":"Content Engagement Depth",
    "Benchmark":"75%+ of users should reach the bottom 75% of long-form content pages, indicating solid engagement depth and scannability.",
    "Definition":"Measures how thoroughly content is consumed.",
    "Goal":"Increase average scroll depth and interaction with in-depth content, indicating user engagement beyond the fold.",
    "Category":"Content",
    "Metric Type":"Composite",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Learning Platform, Publication",
    "More Info":"https:\/\/docs.mapp.com\/docs\/depths-of-engagement-1"
  },
  {
    "KPI Name":"Content Refresh Engagement Lift",
    "Benchmark":"Updating old content should result in a 10\u201330% lift in user engagement, traffic, or time-on-page, based on Google Search Console trends.",
    "Definition":"Engagement increase after content updates.",
    "Goal":"Measure the impact of updated or refreshed content on engagement to validate content strategy improvements.",
    "Category":"Content",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"News Platform, Content Hub",
    "More Info":"https:\/\/www.fastercapital.com\/content\/Content-engagement--Content-Refresh--The-Power-of-a-Content-Refresh-in-Re-engaging-Your-Audience.html"
  },
  {
    "KPI Name":"Conversion Rate",
    "Benchmark":"Conversion rates should fall between 2\u20135% for B2C and 5\u201310% for B2B, according to industry marketing benchmarks.",
    "Definition":"Percentage of users completing a goal.",
    "Goal":"Boost the number of users who complete a desired action (purchase, signup) through optimization of CTAs and flow.",
    "Category":"Conversion",
    "Metric Type":"Quantitative",
    "Design Stage":"Optimization",
    "User Journey Stage":"Acquisition",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Monetized",
    "Applicable Project Types":"eCommerce, Checkout Flow, Lead Form",
    "More Info":"https:\/\/contentsquare.com\/guides\/conversion-rate-optimization\/metrics\/"
  },
  {
    "KPI Name":"Cost per Conversion",
    "Benchmark":"Cost per conversion should be under 10% of average order value for sustainable ROI across paid advertising platforms.",
    "Definition":"Ad spend divided by conversions.",
    "Goal":"Reduce the average cost to acquire a customer through improved conversion paths and ad targeting.",
    "Category":"Conversion",
    "Metric Type":"Quantitative",
    "Design Stage":"Optimization",
    "User Journey Stage":"Acquisition",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"eCommerce, Checkout Flow, Lead Form",
    "More Info":"https:\/\/www.dataflo.io\/metricbase\/cost-per-conversion"
  },
  {
    "KPI Name":"Add-to-Cart Rate",
    "Benchmark":"E-commerce add-to-cart rates should exceed 8%; Amazon benchmarks place typical ranges from 7\u201312% depending on UX and category.",
    "Definition":"Users who add products to cart.",
    "Goal":"Encourage more product interest and intent by increasing the frequency of users adding items to their cart.",
    "Category":"Conversion",
    "Metric Type":"Quantitative",
    "Design Stage":"Optimization",
    "User Journey Stage":"Acquisition",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"eCommerce, Checkout Flow, Lead Form",
    "More Info":"https:\/\/agencyanalytics.com\/kpi-definitions\/add-to-cart-rate"
  },
  {
    "KPI Name":"Checkout Completion Rate",
    "Benchmark":"Checkout completion rate should exceed 80%; top-performing sites often exceed 90% with streamlined cart UX and guest checkout.",
    "Definition":"Percentage completing the checkout process.",
    "Goal":"Ensure a smooth checkout process to increase the percentage of users completing purchases.",
    "Category":"Conversion",
    "Metric Type":"Quantitative",
    "Design Stage":"Optimization",
    "User Journey Stage":"Acquisition",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Monetized",
    "Applicable Project Types":"eCommerce, Checkout Flow, Lead Form",
    "More Info":"https:\/\/www.persado.com\/articles\/checkout-completion-rate\/"
  },
  {
    "KPI Name":"Lead Generation Rate",
    "Benchmark":"Lead form conversion should exceed 15%, with best-in-class forms hitting 20\u201325%, depending on incentive, friction, and channel.",
    "Definition":"Rate of new potential customers collected.",
    "Goal":"Grow the percentage of users who submit their contact info or request demos to fuel marketing and sales.",
    "Category":"Conversion",
    "Metric Type":"Quantitative",
    "Design Stage":"Optimization",
    "User Journey Stage":"Acquisition",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"eCommerce, Checkout Flow, Lead Form",
    "More Info":"https:\/\/www.saleshandy.com\/blog\/lead-generation-statistics\/"
  },
  {
    "KPI Name":"Revenue per Visit",
    "Benchmark":"Revenue per visit should be over $1.00 for DTC sites; high-converting brands exceed $2.00+ when combined with upsell flows.",
    "Definition":"Earnings per site visit.",
    "Goal":"Maximize revenue generated per user session through higher-value conversions and effective upselling.",
    "Category":"Conversion",
    "Metric Type":"Composite",
    "Design Stage":"Optimization",
    "User Journey Stage":"Acquisition",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Monetized",
    "Applicable Project Types":"eCommerce, Checkout Flow, Lead Form",
    "More Info":"https:\/\/www.abtasty.com\/blog\/revenue-per-visitor\/"
  },
  {
    "KPI Name":"Trial-to-Paid Conversion",
    "Benchmark":"SaaS products should convert 20\u201340% of trials to paid users; frictionless onboarding and early feature exposure increase this rate.",
    "Definition":"Trial users who become paying customers.",
    "Goal":"Increase the percentage of users converting from free trials to paid plans by optimizing the onboarding experience.",
    "Category":"Conversion",
    "Metric Type":"Composite",
    "Design Stage":"Optimization",
    "User Journey Stage":"Acquisition",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"eCommerce, Checkout Flow, Lead Form",
    "More Info":"https:\/\/www.lennysnewsletter.com\/p\/what-is-a-good-free-to-paid-conversion"
  },
  {
    "KPI Name":"ROI of Redesign",
    "Benchmark":"Redesign ROI should exceed 150% in revenue or conversion gain within 6 months post-launch, as measured by A\/B testing or analytics.",
    "Definition":"Returns generated from a design change.",
    "Goal":"Measure ROI of a redesign by comparing engagement and conversion metrics before and after launch.",
    "Category":"Conversion",
    "Metric Type":"Composite",
    "Design Stage":"Optimization",
    "User Journey Stage":"Acquisition",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"eCommerce, Checkout Flow, Lead Form",
    "More Info":"https:\/\/www.nngroup.com\/articles\/calculating-roi-design-projects\/"
  },
  {
    "KPI Name":"Premium Feature Exploration",
    "Benchmark":"30%+ of users should engage with premium features within the first session or week, indicating discoverability and perceived value.",
    "Definition":"Users interacting with paid features.",
    "Goal":"Track how many users explore advanced features to assess discoverability and education efforts.",
    "Category":"Conversion",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Freemium App, Content Platform",
    "More Info":"https:\/\/userpilot.com\/blog\/user-engagement-metrics\/"
  },
  {
    "KPI Name":"Design-to-Dev Handoff Time",
    "Benchmark":"Design-to-dev handoff time should be under 24 hours post-approval, using design systems and spec tools (e.g., Zeplin, Figma, or Storybook).",
    "Definition":"Time from design completion to dev.",
    "Goal":"Reduce the time it takes designers and developers to align on deliverables and implement changes.",
    "Category":"Design Ops",
    "Metric Type":"Quantitative",
    "Design Stage":"Development",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Design System, Component Library, Prototyping Tool",
    "More Info":"https:\/\/www.uxpin.com\/studio\/blog\/10-ways-to-improve-design-to-development-handoff\/"
  },
  {
    "KPI Name":"Time from Wireframe to Prototype",
    "Benchmark":"Wireframe-to-prototype cycles should be 5 business days or fewer for typical workflows, accelerating time-to-validation.",
    "Definition":"Speed from sketch to testable prototype.",
    "Goal":"Streamline the design process to reduce the average time it takes to move from wireframe to prototype.",
    "Category":"Design Ops",
    "Metric Type":"Quantitative",
    "Design Stage":"Development",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Design System, Component Library, Prototyping Tool",
    "More Info":"https:\/\/www.linkedin.com\/advice\/1\/how-do-you-manage-your-time-resources-when-wireframing"
  },
  {
    "KPI Name":"Design Bug Report Volume",
    "Benchmark":"Design bugs should not exceed 1 per user per release; tracked through QA testing and post-launch feedback.",
    "Definition":"Reported issues in design implementation.",
    "Goal":"Lower the number of design-related bugs reported post-handoff by improving documentation and QA practices.",
    "Category":"Design Ops",
    "Metric Type":"Composite",
    "Design Stage":"Development",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Design System, Component Library, Prototyping Tool",
    "More Info":"https:\/\/www.linkedin.com\/advice\/3\/what-best-strategies-managing-high-volume-bug-okykc"
  },
  {
    "KPI Name":"Feature Cycle Time",
    "Benchmark":"Feature cycle time (ideation to release) should be under 2 weeks for iterative teams using Agile sprints or Lean UX.",
    "Definition":"Time to release a new feature.",
    "Goal":"Shorten the average time from feature design to launch by reducing bottlenecks in the dev cycle.",
    "Category":"Design Ops",
    "Metric Type":"Quantitative",
    "Design Stage":"Development",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Design System, Component Library, Prototyping Tool",
    "More Info":"https:\/\/martinfowler.com\/bliki\/CycleTime.html"
  },
  {
    "KPI Name":"UX-Driven Retention Rate",
    "Benchmark":"Retention should show 15%+ improvement attributable to UX improvements based on cohort analysis and A\/B testing.",
    "Definition":"Retention linked to UX improvements.",
    "Goal":"Track how well UX improvements contribute to long-term user retention rates.",
    "Category":"Design Ops",
    "Metric Type":"Qualitative",
    "Design Stage":"Development",
    "User Journey Stage":"All",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Monetized",
    "Applicable Project Types":"Enterprise System, Brand Ecosystem",
    "More Info":"https:\/\/blog.icx.co\/en\/user-experience\/user-experience\/how-does-ux-design-improve-customer-retention"
  },
  {
    "KPI Name":"Click-through Rate (CTR)",
    "Benchmark":"Click-through rates of 2\u20135% are standard for primary CTAs; higher for personalized or urgency-driven messages.",
    "Definition":"Ratio of clicks to views.",
    "Goal":"Improve CTRs on marketing and in-app campaigns by optimizing copy, design, and placement.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Landing Page, Marketing Site, Content Hub",
    "More Info":"https:\/\/www.optimizely.com\/optimization-glossary\/click-through-rate\/"
  },
  {
    "KPI Name":"Time on Page",
    "Benchmark":"Time on page should exceed 45 seconds for core content or product pages, indicating user interest and readability.",
    "Definition":"Time spent on one page.",
    "Goal":"Ensure users remain engaged with content by increasing the average time spent on key pages.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Landing Page, Marketing Site, Content Hub",
    "More Info":"https:\/\/docs.simpleanalytics.com\/explained\/time-on-page"
  },
  {
    "KPI Name":"Session Duration",
    "Benchmark":"Average session duration should exceed 2 minutes; shorter sessions indicate potential friction or misaligned content.",
    "Definition":"Total time spent per visit.",
    "Goal":"Increase session duration as a proxy for sustained engagement and perceived value of the product.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Landing Page, Marketing Site, Content Hub",
    "More Info":"https:\/\/jetpack.com\/resources\/session-duration\/"
  },
  {
    "KPI Name":"Interactions per Session",
    "Benchmark":"Engaged users should perform 4+ meaningful interactions per session (clicks, scrolls, video plays, etc.).",
    "Definition":"Average user actions per visit.",
    "Goal":"Boost the number of meaningful interactions per session to reflect active and engaged use.",
    "Category":"Engagement",
    "Metric Type":"Composite",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Landing Page, Marketing Site, Content Hub",
    "More Info":"https:\/\/www.productstash.xyz\/product-metrics\/user-actions-per-session"
  },
  {
    "KPI Name":"Active Users (DAU\/WAU\/MAU)",
    "Benchmark":"Healthy DAU\/MAU ratio is 20%+; product stickiness is indicated by higher ratios in tools like Mixpanel or Amplitude.",
    "Definition":"Daily\/weekly\/monthly active user counts.",
    "Goal":"Maintain high levels of daily, weekly, and monthly active users to gauge overall product health.",
    "Category":"Engagement",
    "Metric Type":"Composite",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Landing Page, Marketing Site, Content Hub",
    "More Info":"https:\/\/userpilot.com\/blog\/dau-wau-mau\/"
  },
  {
    "KPI Name":"Frequency of Visits",
    "Benchmark":"AKA \"Frequency And Recency\", return visitors should account for 30\u201350% of traffic on sticky or content-rich products.",
    "Definition":"Average number visits within a timeframe.",
    "Goal":"Encourage frequent return visits through habit-forming features or strong user value.",
    "Category":"Engagement",
    "Metric Type":"Composite",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Landing Page, Marketing Site, Content Hub",
    "More Info":"https:\/\/www.nngroup.com\/articles\/frequency-recency\/"
  },
  {
    "KPI Name":"Retention Rate",
    "Benchmark":"Day 7 retention of 25%+ is ideal in most SaaS and mobile apps; benchmark varies slightly by industry.",
    "Definition":"Percentage of users who return over a set period.",
    "Goal":"Maximize the percentage of users who remain active over time to minimize churn.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Monetized",
    "Applicable Project Types":"Mobile App, SaaS",
    "More Info":"https:\/\/www.appsflyer.com\/glossary\/retention-rate\/"
  },
  {
    "KPI Name":"Daily Active Users (DAU)",
    "Benchmark":"Daily active users should equal at least 10\u201320% of MAU for consistent engagement in sticky platforms.",
    "Definition":"Unique users active daily.",
    "Goal":"Track how many users engage with the product daily to assess stickiness and habitual usage.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"App, Platform",
    "More Info":"https:\/\/www.adjust.com\/glossary\/daily-active-users\/"
  },
  {
    "KPI Name":"Weekly Active Users (WAU)",
    "Benchmark":"Weekly active users should comprise 40\u201360% of MAU for SaaS and productivity platforms.",
    "Definition":"Score measuring UI consistency across designs.",
    "Goal":"Monitor weekly engagement trends to support cohort analysis and retention strategies.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"App, Platform",
    "More Info":"https:\/\/www.appsflyer.com\/glossary\/weekly-active-users\/"
  },
  {
    "KPI Name":"Scroll Depth",
    "Benchmark":"Scroll depth should show that 75% of users reach halfway down most key pages; deep pages may vary.",
    "Definition":"How far users scroll on a page.",
    "Goal":"Increase how far users scroll down a page, especially on content-rich experiences.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Websites, Landing Pages",
    "More Info":"https:\/\/mailchimp.com\/resources\/scroll-depth\/"
  },
  {
    "KPI Name":"Average Number of Sessions per User",
    "Benchmark":"Average of 3+ sessions per user per month indicates sustained value; higher for social or utility apps.",
    "Definition":"Avg. sessions per user in given timeframe.",
    "Goal":"Boost the average number of sessions per user by delivering ongoing value and engagement opportunities.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Web App, Game",
    "More Info":"https:\/\/userpilot.com\/blog\/number-of-sessions-per-user\/"
  },
  {
    "KPI Name":"Time to First Interaction (TTFI)",
    "Benchmark":"Time to first interaction (TTFI) should be under 1.5s for 90%+ of sessions; key for perceived performance, according to Google Web Vitals.",
    "Definition":"Time from load to first user action.",
    "Goal":"Reduce the time it takes users to engage with the interface after landing to improve first impressions.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Web App, Game",
    "More Info":"https:\/\/www.akamai.com\/blog\/developers\/beyond-cwv-more-performance-metrics-to-monitor-part-3-of-5"
  },
  {
    "KPI Name":"Notification Interaction Rate",
    "Benchmark":"Notification interaction rate should exceed 40% for optional opt-in push or in-app messages, according to benchmarks from OneSignal\u00a0",
    "Definition":"User engagement with app notifications.",
    "Goal":"Track user engagement with system or marketing notifications to assess relevance and timing.",
    "Category":"Engagement",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Social Platform, Messaging App",
    "More Info":"https:\/\/arena.im\/marketing-growth\/understand-push-notification-effectiveness\/"
  },
  {
    "KPI Name":"Statistical Significance",
    "Benchmark":"Statistical significance in tests should be set at p < 0.05 with proper sample size to validate design changes; this is standard in A\/B testing per Optimizely.",
    "Definition":"Confidence level of test results (vs random chance)",
    "Goal":"Ensure that A\/B test results are statistically significant to confidently inform product decisions.",
    "Category":"Experimentation",
    "Metric Type":"Composite",
    "Design Stage":"Validation",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Any",
    "More Info":"https:\/\/amplitude.com\/explore\/experiment\/statistical-significance-guide"
  },
  {
    "KPI Name":"Experiment Impact Score",
    "Benchmark":"Experiment impact score should reflect at least a 10% positive movement in primary KPIs over control, as recommended by product-led growth frameworks like Reforge and Amplitude.",
    "Definition":"Effect size from experiment.",
    "Goal":"Quantify the measurable change resulting from experiments to determine business or UX impact.",
    "Category":"Experimentation",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Any",
    "More Info":"https:\/\/www.statsig.com\/perspectives\/successful-metrics-in-experimentation"
  },
  {
    "KPI Name":"Menu Discovery Rate",
    "Benchmark":"Menu discoverability should be 70%+ on first glance; test with 5-second tests and click heatmaps per Nielsen Norman Group guidelines\u00a0",
    "Definition":"Users who find and use menu.",
    "Goal":"Track how easily users find items in navigation menus to improve overall information architecture.",
    "Category":"Findability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Websites, Platforms",
    "More Info":"https:\/\/www.nngroup.com\/articles\/menu-design\/"
  },
  {
    "KPI Name":"Search Success Rate",
    "Benchmark":"Search success rate must be 80%+ with no zero-results pages for most common queries, based on Baymard Institute usability benchmarks",
    "Definition":"Users finding desired results via search.",
    "Goal":"Increase successful search queries to improve content discoverability and search UX.",
    "Category":"Findability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, CMS",
    "More Info":"https:\/\/searchanise.io\/blog\/how-to-measure-search-effectiveness\/"
  },
  {
    "KPI Name":"Feature Discovery Time",
    "Benchmark":"Users should discover core features in <5 minutes using onboarding, visual hierarchy, and contextual cues, a benchmark promoted by Appcues and Userpilot for Product Led Growth strategies.",
    "Definition":"Time to first feature use.",
    "Goal":"Reduce the time it takes new users to discover key features to accelerate product understanding.",
    "Category":"Findability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Complex Platform, Creative Tool",
    "More Info":"https:\/\/www.wudpecker.io\/blog\/tracking-feature-discovery-metrics-what-to-measure-and-why"
  },
  {
    "KPI Name":"Funnel Drop-off Rate",
    "Benchmark":"Drop-off per funnel step should remain under 20%; identify and fix friction points per stage, per Mixpanel funnel reports and Amplitude best practices",
    "Definition":"Users exiting before completing steps.",
    "Goal":"Identify and optimize points where users drop off in funnels to reduce friction and increase completions.",
    "Category":"Flow",
    "Metric Type":"Quantitative",
    "Design Stage":"Prototyping",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Onboarding Flow, SaaS Platform",
    "More Info":"https:\/\/contentsquare.com\/blog\/funnel-drop-off-rate\/"
  },
  {
    "KPI Name":"Step Completion Time",
    "Benchmark":"Step completion time should be under 30 seconds per step for multi-step forms or wizards, a heuristic used in form UX design by UXMatters.",
    "Definition":"Time to complete each step.",
    "Goal":"Improve the speed at which users can complete each step in multi-step tasks or flows.",
    "Category":"Flow",
    "Metric Type":"Quantitative",
    "Design Stage":"Prototyping",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Onboarding Flow, SaaS Platform",
    "More Info":"https:\/\/designsystem.digital.gov\/patterns\/complete-a-complex-form\/progress-easily\/"
  },
  {
    "KPI Name":"Tooltip Interaction Rate",
    "Benchmark":"Typical interaction rates for tooltips and onboarding hints via platforms like Pendo, WalkMe, and Appcues usually fall in the 8\u201315% range.",
    "Definition":"Users engaging with tooltip info.",
    "Goal":"Track interaction with tooltips to ensure onboarding cues are visible, helpful, and not intrusive.",
    "Category":"Interaction",
    "Metric Type":"Quantitative",
    "Design Stage":"Prototyping",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Internal Tools, Dashboards",
    "More Info":"https:\/\/www.nngroup.com\/articles\/tooltip-guidelines\/"
  },
  {
    "KPI Name":"Gesture Adoption Rate",
    "Benchmark":"AKA \"Gesture Recognition\", adoption rates vary widely by type. Without onboarding, swipe gestures see 20\u201335% adoption, while long-press and double-tap fall below 15%. With onboarding support, adoption increases significantly\u2014swipe can reach 60%, drag-and-drop 40%, and pinch-to-zoom up to 50%. Clear guidance and visual cues play a critical role in improving discoverability and engagement.",
    "Definition":"Use of gestures in apps.",
    "Goal":"Monitor how often users successfully use gestures (e.g. swipe, pinch) to inform mobile UX improvements.",
    "Category":"Interaction",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Mobile App, Touchscreen Interface",
    "More Info":"https:\/\/www.codebridge.tech\/articles\/the-impact-of-gestures-on-mobile-user-experience"
  },
  {
    "KPI Name":"Voice Command Success Rate",
    "Benchmark":"AKA \"Speech Recognition Accuracy\" Voice command accuracy must exceed 70% for most common commands during usability testing, in line with Amazon Alexa and Google Assistant benchmarks ",
    "Definition":"Successful voice commands processed.",
    "Goal":"Ensure high success rates for voice commands where supported, indicating intuitive voice UX.",
    "Category":"Interaction",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Voice Interface, Smart Device App",
    "More Info":"https:\/\/moldstud.com\/articles\/p-smart-home-voice-assistants-siri-vs-alexa-vs-google-assistant"
  },
  {
    "KPI Name":"First Time User Task Success",
    "Benchmark":"80%+ of new users should complete a core task unaided within the first session, as recommended in UX testing by Steve Krug (Don't Make Me Think).",
    "Definition":"New users completing tasks correctly.",
    "Goal":"Measure the percentage of new users who successfully complete core tasks during their first session.",
    "Category":"Onboarding",
    "Metric Type":"Qualitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Mobile App, Dashboard",
    "More Info":"https:\/\/www.heliosdesign.com\/blog\/web\/insights-from-dont-make-me-think-by-steve-krug.html"
  },
  {
    "KPI Name":"Abandonment During Onboarding",
    "Benchmark":"Onboarding abandonment should remain below 40% after the initial step for product-led growth success, per Appcues onboarding benchmark data.",
    "Definition":"Drop-offs during initial onboarding.",
    "Goal":"Reduce drop-offs during onboarding by simplifying the experience and setting clear user expectations.",
    "Category":"Onboarding",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Web App, SaaS",
    "More Info":"https:\/\/www.abbyy.com\/intelligent-enterprise\/why-customers-abandon-onboarding-processes\/"
  },
  {
    "KPI Name":"Tour Completion Rate",
    "Benchmark":"60%+ of users should complete a tour during first use to ensure full feature exposure, according to benchmarks from Chameleon and Userlane.",
    "Definition":"Percent completion walkthrough.",
    "Goal":"Increase the percentage of users completing guided tours to enhance onboarding and product discovery.",
    "Category":"Onboarding",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Web App, SaaS",
    "More Info":"https:\/\/productfruits.com\/blog\/product-tour-metrics\/"
  },
  {
    "KPI Name":"Load Time",
    "Benchmark":"Page load time (Fully Loaded) should be under 3 seconds for 80% of users to minimize bounce, as recommended by Google Lighthouse and Core Web Vitals guidelines.",
    "Definition":"Page or app load duration.",
    "Goal":"Minimize page load time to improve user satisfaction and reduce bounce rates.",
    "Category":"Performance",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Awareness",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"All",
    "More Info":"https:\/\/agencyanalytics.com\/kpi-definitions\/page-load-time"
  },
  {
    "KPI Name":"Layout Responsiveness Score",
    "Benchmark":"Layout responsiveness should maintain a Lighthouse score above 90, ensuring visual elements reflow correctly across devices and avoiding cumulative layout shift (CLS) issues.",
    "Definition":"Visual layout responsiveness rating.",
    "Goal":"Measure how well the layout adapts across screen sizes to maintain usability and visual integrity.",
    "Category":"Performance",
    "Metric Type":"Quantitative",
    "Design Stage":"Development",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Responsive Website, Progressive Web App",
    "More Info":"https:\/\/www.nngroup.com\/articles\/breakpoints-in-responsive-design\/"
  },
  {
    "KPI Name":"Time to Interactive (TTI)",
    "Benchmark":"Page interactivity (TTI) should occur within 3.8 seconds for 75% of sessions; longer delays negatively affect perceived speed and user control per Web Vitals ",
    "Definition":"Time to interactive page state.",
    "Goal":"Track how long it takes for pages to become interactive after loading to assess perceived speed.",
    "Category":"Performance",
    "Metric Type":"Quantitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Awareness",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Web App, Image-Heavy Site",
    "More Info":"https:\/\/agencyanalytics.com\/kpi-definitions\/time-to-interactive"
  },
  {
    "KPI Name":"Component Loading Speed",
    "Benchmark":"Individual UI components should load within 2 seconds of user interaction, especially buttons, dropdowns, and critical page sections; this is aligned with Shopify and Salesforce UX performance guidelines.",
    "Definition":"Speed of UI component load.",
    "Goal":"Measure how quickly individual components appear and render to avoid loading frustration.",
    "Category":"Performance",
    "Metric Type":"Quantitative",
    "Design Stage":"Development",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Web App, Dynamic Dashboard",
    "More Info":"https:\/\/www.salesforce.com\/blog\/want-faster-page-load-times-design-for-it\/"
  },
  {
    "KPI Name":"Animation Performance Score",
    "Benchmark":"Animation performance should maintain 60 frames per second (FPS) to prevent stutter, tested using Chrome DevTools or equivalent, per Google's rendering performance metrics.",
    "Definition":"Smoothness and stability of animations.",
    "Goal":"Ensure animations perform smoothly without lag to maintain a polished, responsive interface.",
    "Category":"Performance",
    "Metric Type":"Quantitative",
    "Design Stage":"Development",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Interactive Website, Mobile Game",
    "More Info":"https:\/\/www.viget.com\/articles\/animation-performance-101-measuring-with-dev-tools\/"
  },
  {
    "KPI Name":"API Response Time",
    "Benchmark":"API response times should be under 300ms for mission-critical data; under 500ms for non-blocking background tasks, per recommendations from Google and AWS latency benchmarks.",
    "Definition":"Server reply time to requests.",
    "Goal":"Track backend response times to optimize loading speed and user-perceived responsiveness.",
    "Category":"Performance",
    "Metric Type":"Quantitative",
    "Design Stage":"Development",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Data-Heavy Application, Real-time Tool",
    "More Info":"https:\/\/odown.com\/blog\/what-is-a-good-api-response-time\/ "
  },
  {
    "KPI Name":"Dark Mode Usage Rate",
    "Benchmark":"Dark mode usage should exceed 25% across opt-in toggles; this benchmark is supported by UX case studies from GitHub, Twitter",
    "Definition":"Users opting for dark mode.",
    "Goal":"Measure adoption of dark mode to inform theming priorities and user preferences.",
    "Category":"Personalization",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Engagement",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Mobile App, Desktop App",
    "More Info":"https:\/\/www.nngroup.com\/articles\/dark-mode-users-issues\/"
  },
  {
    "KPI Name":"User Settings Adjustment Rate",
    "Benchmark":"A realistic benchmark for user settings adjustment rate is 10\u201325% of active users within the first month of use. This reflects expected behavior for customizable products, where only a subset of users engage deeply with personalization. Source: UX Patterns, Amplitude data.",
    "Definition":"Users changing default settings.",
    "Goal":"Track how often users customize settings to inform personalization features and user needs.",
    "Category":"Personalization",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Productivity App, Professional Tool",
    "More Info":"https:\/\/docs.arcadia.com\/v2022-12-21-Signal\/docs\/user-adjusted-rates"
  },
  {
    "KPI Name":"Personalization Algorithm Efficacy",
    "Benchmark":"Personalized content should improve click-through rate by 10\u201320% over static alternatives; based on A\/B test results shared by Adobe Target and Optimizely.",
    "Definition":"Accuracy of personalization outcomes.",
    "Goal":"Evaluate how well personalization algorithms are driving relevance and engagement.",
    "Category":"Personalization",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Recommendation Engine",
    "More Info":"https:\/\/www.nature.com\/articles\/s41599-025-04593-6"
  },
  {
    "KPI Name":"NPS Verbatim Themes",
    "Benchmark":"Top 5 themes from NPS verbatim responses should cover 70%+ of user comments, helping focus product or service improvements based on user language, per Satmetrix and Delighted NPS analysis practices.",
    "Definition":"Common patterns in NPS comments.",
    "Goal":"Analyze open-ended NPS feedback to surface recurring themes and user sentiment.",
    "Category":"Qualitative Feedback",
    "Metric Type":"Qualitative",
    "Design Stage":"Testing",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Support Center, Feedback Tool",
    "More Info":"https:\/\/getthematic.com\/assets\/downloads\/AnalysisOfNPSVerbatims_Thematic_WhitePaper_2021.pdf"
  },
  {
    "KPI Name":"Feedback Volume per Feature",
    "Benchmark":"A realistic benchmark for feedback volume per feature is 1\u20133% of active users monthly. This rate reflects typical user engagement levels and allows teams to gather actionable input without over-relying on broad participation. Source: Hotjar, industry UX norms.",
    "Definition":"Comments received by feature.",
    "Goal":"Measure how much feedback each feature generates to identify issues or strong engagement points.",
    "Category":"Qualitative Feedback",
    "Metric Type":"Qualitative",
    "Design Stage":"Testing",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Support Center, Feedback Tool",
    "More Info":"https:\/\/www.savio.io\/blog\/from-feedback-to-product-features-what-it-takes-and-when-to-implement\/"
  },
  {
    "KPI Name":"NPS Verbatim Themes+A53",
    "Benchmark":"Ensure the top 5 recurring response themes across NPS comments align with product pillars and are represented in 70%+ of qualitative feedback entries, as recommended in Qualtrics NPS management.",
    "Definition":"Enhanced analysis of NPS feedback.",
    "Goal":"Combine sentiment analysis and user clustering to extract themes from NPS verbatims at scale.",
    "Category":"Qualitative Feedback",
    "Metric Type":"Qualitative",
    "Design Stage":"Testing",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Support Center, Feedback Tool",
    "More Info":"https:\/\/support.pendo.io\/hc\/en-us\/articles\/7942098333723-Manage-NPS-themes-and-insights"
  },
  {
    "KPI Name":"Support Ticket Reduction",
    "Benchmark":"Support ticket volume should drop by 10\u201320% within 30\u201360 days after redesigns or usability fixes; benchmark used in Zendesk and Intercom support analysis.",
    "Definition":"Decrease in help requests.",
    "Goal":"Reduce the number of support tickets post-launch by improving UX and self-service documentation.",
    "Category":"Qualitative Feedback",
    "Metric Type":"Qualitative",
    "Design Stage":"Testing",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Support Center, Feedback Tool",
    "More Info":"https:\/\/document360.com\/blog\/reduce-support-tickets\/"
  },
  {
    "KPI Name":"Survey Summary Score",
    "Benchmark":"Average survey scores should be \u22654.0\/5 with a 10%+ response rate; guidance derived from Qualaroo and Typeform benchmark studies.",
    "Definition":"Average qualitative or quantitative survey rating.",
    "Goal":"Summarize survey scores across experiences to provide a benchmark for overall satisfaction.",
    "Category":"Qualitative Feedback",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"All",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Support Center, Feedback Tool",
    "More Info":"https:\/\/www.surveymonkey.com\/mp\/survey-analysis-reporting\/"
  },
  {
    "KPI Name":"Churn Rate",
    "Benchmark":"Monthly churn rate should stay under 5% in SaaS and under 2% for enterprise contracts; according to SaaS industry reports from Baremetrics and ChartMogul.",
    "Definition":"Users leaving the platform.",
    "Goal":"Lower churn by identifying and addressing patterns in user disengagement or frustration.",
    "Category":"Retention",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Monetized",
    "Applicable Project Types":"Subscription App, Email Flow",
    "More Info":"https:\/\/www.investopedia.com\/terms\/c\/churnrate.asp"
  },
  {
    "KPI Name":"Repeat Visit Rate",
    "Benchmark":"Repeat visit rate should exceed 30% for content-based or service-driven tools; 40\u201350% indicates strong user value, per Google Analytics benchmarks.",
    "Definition":"Users returning after initial visit.",
    "Goal":"Encourage repeat visits to boost loyalty and long-term engagement.",
    "Category":"Retention",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Subscription App, Email Flow",
    "More Info":"https:\/\/lifesight.io\/glossary\/repeat-visits\/"
  },
  {
    "KPI Name":"CSAT (Customer Satisfaction Score)",
    "Benchmark":"CSAT (Customer Satisfaction Score) should average 4.2+ out of 5, with responses collected after key workflows; this threshold is recommended by HubSpot and Zendesk.",
    "Definition":"Customer happiness rating.",
    "Goal":"Track satisfaction based on survey responses to measure perceived experience quality.",
    "Category":"Retention",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Subscription App, Email Flow",
    "More Info":"https:\/\/www.qualtrics.com\/experience-management\/customer\/what-is-csat\/"
  },
  {
    "KPI Name":"Activation Rate",
    "Benchmark":"Activation rate between 40\u201360% within the first session\/session+1 is typical; this comes from Appcues' State of Product Onboarding Report.",
    "Definition":"Users reaching key value quickly.",
    "Goal":"Increase the percentage of users completing activation milestones within a set timeframe.",
    "Category":"Retention",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Subscription App, Email Flow",
    "More Info":"https:\/\/www.klipfolio.com\/resources\/kpi-examples\/saas\/activation-rate"
  },
  {
    "KPI Name":"Renewal Rate",
    "Benchmark":"Renewal rate should exceed 85% for SaaS; benchmark referenced in OpenView and SaaS Capital retention benchmarks.",
    "Definition":"Subscription renewal frequency.",
    "Goal":"Measure renewal rates to evaluate product value over long-term use.",
    "Category":"Retention",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Monetized",
    "Applicable Project Types":"Subscription App, Email Flow",
    "More Info":"https:\/\/www.chargebee.com\/resources\/glossaries\/what-is-renewal-rate\/"
  },
  {
    "KPI Name":"System Usability Scale (SUS)",
    "Benchmark":"System Usability Scale (SUS) score of 70+ is considered usable; 85+ indicates excellent UX per Brooke\u2019s SUS standard",
    "Definition":"Overall usability rating.",
    "Goal":"Track usability via standardized SUS scoring to assess ease of use and satisfaction.",
    "Category":"Satisfaction",
    "Metric Type":"Qualitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Platform",
    "More Info":"https:\/\/www.interaction-design.org\/literature\/article\/system-usability-scale"
  },
  {
    "KPI Name":"Net Promoter Score (NPS)",
    "Benchmark":"Net Promoter Score (NPS) should exceed 30 for B2C and 50 for B2B to be considered strong; this range is supported by Bain & Co. and Retently ",
    "Definition":"Measures customer loyalty.",
    "Goal":"Use NPS to gauge user loyalty and likelihood to recommend the product.",
    "Category":"Satisfaction",
    "Metric Type":"Qualitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"SaaS, Mobile App",
    "More Info":"https:\/\/www.ibm.com\/think\/topics\/net-promoter-score"
  },
  {
    "KPI Name":"Customer Effort Score (CES)",
    "Benchmark":"Customer Effort Score (CES) should stay below 3 on a 1\u20137 scale; based on recommendations from Gartner and published CES methodology\u00a0",
    "Definition":"Ease of user interaction.",
    "Goal":"Measure the perceived ease of completing tasks to identify friction in workflows.",
    "Category":"Satisfaction",
    "Metric Type":"Qualitative",
    "Design Stage":"Validation",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Support Interfaces, Forms",
    "More Info":"https:\/\/www.ibm.com\/think\/topics\/customer-effort-score"
  },
  {
    "KPI Name":"Security Feature Adoption",
    "Benchmark":"At least 50% of users should activate or configure one key security feature (e.g., 2FA, email verification) within first 7 days of onboarding, as recommended in security onboarding by Auth0 and Okta.",
    "Definition":"Users enabling security features.",
    "Goal":"Track usage of built-in security features (2FA, privacy settings) to ensure user protection.",
    "Category":"Security",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Banking App, Healthcare Portal",
    "More Info":"https:\/\/www.sciencedirect.com\/topics\/engineering\/security-feature"
  },
  {
    "KPI Name":"Average Support Tickets per User",
    "Benchmark":"Maintain fewer than 0.1 support tickets per active user per month; industry threshold from Freshdesk, Intercom, and in-app support providers.",
    "Definition":"Support load per user.",
    "Goal":"Lower average support tickets per user by improving self-help resources and UX clarity.",
    "Category":"Support",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Retention",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"SaaS, Platform",
    "More Info":"https:\/\/www.fullview.io\/blog\/support-stats"
  },
  {
    "KPI Name":"Task Completion Rate",
    "Benchmark":"AKA \"Success Rate\" Task completion rates should exceed 80% during usability tests or analytics tracking for flows like signup, file upload, or checkout, according to NNGroup usability benchmarks.",
    "Definition":"Tasks completed successfully.",
    "Goal":"Track the percentage of users completing defined tasks successfully to assess UX clarity.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/www.monitask.com\/en\/business-glossary\/task-completion-rate"
  },
  {
    "KPI Name":"Time on Task",
    "Benchmark":"Time-on-task should stay under 2 minutes for standard flows; supported by industry best practices from Nielsen Norman Group and UXPA.",
    "Definition":"Duration to finish task.",
    "Goal":"Measure how long it takes users to complete tasks as an indicator of efficiency.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/www.productstash.xyz\/product-metrics\/time-on-task"
  },
  {
    "KPI Name":"Error Rate",
    "Benchmark":"Error rate in user flows should be under 3%; consistent logging of validation, server, or navigation errors helps isolate and resolve core UX issues.",
    "Definition":"Frequency of user mistakes.",
    "Goal":"Track the frequency of errors users encounter to identify usability or flow issues.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/adapty.io\/glossary\/error-rate\/"
  },
  {
    "KPI Name":"Rage Clicks",
    "Benchmark":"Rage clicks should be under 2% of total clicks; metric is standard in FullStory and Smartlook product analytics dashboards.",
    "Definition":"Rapid clicking out of frustration.",
    "Goal":"Identify rage clicks to find frustration points or broken interactions.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/www.fullstory.com\/blog\/rage-clicks\/"
  },
  {
    "KPI Name":"Dead Clicks",
    "Benchmark":"Dead clicks (clicks with no action) should be under 3%; identified as a signal of UX failure by Hotjar and Contentsquare analytics.",
    "Definition":"Unresponsive click attempts.",
    "Goal":"Track dead clicks to identify elements users think are clickable but are not.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/mouseflow.com\/blog\/understanding-and-fixing-dead-clicks-on-your-website\/"
  },
  {
    "KPI Name":"Form Abandonment Rate",
    "Benchmark":"Form abandonment should remain under 60% on desktop and under 70% on mobile; informed by Baymard Institute checkout form benchmarks.",
    "Definition":"Percentage of users who don\u2019t complete a form.",
    "Goal":"Reduce form abandonment by optimizing flow, field order, and clarity.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/www.fullstory.com\/blog\/form-abandonment\/"
  },
  {
    "KPI Name":"First Click Accuracy",
    "Benchmark":"First click accuracy should exceed 75% on key tasks in usability testing; cited in usability testing playbooks from NNGroup and MeasuringU.",
    "Definition":"Correct first interaction.",
    "Goal":"Measure the accuracy of user\u2019s first clicks to gauge intuitive navigation and layout.",
    "Category":"Usability",
    "Metric Type":"Composite",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/medium.com\/@patrickward_\/first-click-testing-8c1e9250bf90"
  },
  {
    "KPI Name":"Usability Score (SUS\/SUPR-Q)",
    "Benchmark":"SUS scores over 70 or SUPR-Q scores over 4.0 indicate solid usability; based on standardized interpretation from Jeff Sauro and UX research platforms.",
    "Definition":"Standard usability evaluation.",
    "Goal":"Use SUS or SUPR-Q scores to benchmark perceived usability and quality across interfaces.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/measuringu.com\/suprq-sus\/"
  },
  {
    "KPI Name":"Learnability Rate",
    "Benchmark":"Learnability rate should exceed 80%, where users can repeat a core task unaided on their second session; recommended by usability.gov and NNGroup.",
    "Definition":"How quickly users learn.",
    "Goal":"Track how quickly users learn to complete tasks with minimal guidance.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Dashboard, Internal Tool, Mobile App",
    "More Info":"https:\/\/www.nngroup.com\/articles\/measure-learnability\/"
  },
  {
    "KPI Name":"Success Rate",
    "Benchmark":"Success rate for core user tasks should exceed 85%; this is a typical benchmark in task-based testing scenarios across usability.gov guidelines.",
    "Definition":"Users achieving goals.",
    "Goal":"Measure the overall success rate of task completion during usability testing.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Form, Checkout Flow",
    "More Info":"https:\/\/khoros.com\/blog\/success-rate"
  },
  {
    "KPI Name":"Cognitive Load Score",
    "Benchmark":"Cognitive load scores should be under 3 on a 1\u20137 NASA-TLX scale or equivalent; cited in UX surveys from SAP, IBM, and academic literature.",
    "Definition":"Mental effort required.",
    "Goal":"Track cognitive strain to assess how mentally demanding the interface is for users.",
    "Category":"Usability",
    "Metric Type":"Qualitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"B2B",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Data Dashboard, Analytics Tool",
    "More Info":"https:\/\/digital.ahrq.gov\/health-it-tools-and-resources\/evaluation-resources\/workflow-assessment-health-it-toolkit\/all-workflow-tools\/nasa-task-load-index"
  },
  {
    "KPI Name":"Form Field Error Rate",
    "Benchmark":"Field-level error rates should stay below 5% in submitted forms; aligned with form usability standards from Baymard and Wroblewski's \"Web Form Design\" principles. ",
    "Definition":"Errors per field input.",
    "Goal":"Measure how often users encounter and correct errors in form fields.",
    "Category":"Usability",
    "Metric Type":"Quantitative",
    "Design Stage":"Testing",
    "User Journey Stage":"Activation",
    "B2B\/B2C":"Both",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Registration Flow, Data Entry Tool",
    "More Info":"https:\/\/www.nngroup.com\/articles\/errors-forms-design-guidelines\/"
  },
  {
    "KPI Name":"Social Share Rate",
    "Benchmark":"Social share rate should hit 1\u20133% for marketing pages or viral content; this benchmark is cited by Buffer, BuzzSumo, and Sprout Social.",
    "Definition":"Content shared to social media.",
    "Goal":"Track how frequently users share content to assess social engagement.",
    "Category":"Virality",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/agencyanalytics.com\/kpi-definitions\/social-media-shares"
  },
  {
    "KPI Name":"Like \/ Reaction Rate",
    "Benchmark":"Like or reaction rate should exceed 4% per content post in social or community apps; based on Facebook and LinkedIn engagement metric reports.",
    "Definition":"Positive user responses.",
    "Goal":"Track likes or emoji reactions to measure lightweight social approval or enjoyment.",
    "Category":"Virality",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/blog.hootsuite.com\/average-engagement-rate\/"
  },
  {
    "KPI Name":"Comment Rate",
    "Benchmark":"Comment rate over 1% shows deeper engagement; often measured using content analytics tools like Disqus, Medium, or Reddit data.",
    "Definition":"User commenting activity.",
    "Goal":"Track comment activity to assess engagement and conversation around content.",
    "Category":"Virality",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/agencyanalytics.com\/kpi-definitions\/comments"
  },
  {
    "KPI Name":"Bookmark Rate \/ Save Rate",
    "Benchmark":"Bookmark\/save rate should exceed 2% on resource-heavy, reference-style, or inspirational content; indicates perceived future value.",
    "Definition":"Content saved for later.",
    "Goal":"Track bookmarks\/saves as a signal of content value or future intent.",
    "Category":"Virality",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/popularpays.com\/blog\/navigating-social-media-metrics-2025-guide"
  },
  {
    "KPI Name":"Predictive Churn Risk",
    "Benchmark":"Predictive churn models should reach at least 80% accuracy for 7\u201314 day churn forecasting; benchmarked by Mixpanel, Gainsight PX, and Retain.ai.",
    "Definition":"Likelihood of user departure.",
    "Goal":"Use behavior and data signals to anticipate users at risk of leaving and take proactive action.",
    "Category":"AI",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Monetized",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/docs.airship.com\/guides\/messaging\/data\/predictive\/predictive-churn\/"
  },
  {
    "KPI Name":"AI Feedback Loop Rate",
    "Benchmark":"AI feedback loop (e.g., retraining from user edits) should result in 85%+ improved accuracy or relevance; cited in OpenAI and HuggingFace fine-tuning results.",
    "Definition":"How often AI recommendations are acted on.",
    "Goal":"Measure how often users contribute feedback to help improve AI-driven results.",
    "Category":"AI",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/www.zendesk.com.br\/blog\/ai-feedback-loop\/#"
  },
  {
    "KPI Name":"AI Feature Adoption Rate",
    "Benchmark":"AI feature adoption should hit 30\u201350% within the first two weeks of exposure; benchmarked by tools like Notion AI, Grammarly, and GitHub Copilot.",
    "Definition":"% of users who engage with AI-powered features.",
    "Goal":"Track usage rates of AI-powered features to assess adoption and value.",
    "Category":"AI",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/resources.github.com\/learn\/pathways\/copilot\/essentials\/measuring-the-impact-of-github-copilot\/"
  },
  {
    "KPI Name":"AI Override Rate",
    "Benchmark":"AI override rate (e.g., when users reject or undo AI decisions) should be under 10% in mature systems; based on product feedback studies from Jasper, GitHub Copilot, and Figma AI.",
    "Definition":"% of times users reject, edit, override AI output.",
    "Goal":"Track how often users reject or undo AI suggestions to gauge trust and reliability.",
    "Category":"AI",
    "Metric Type":"Quantitative",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/resources.github.com\/learn\/pathways\/copilot\/essentials\/measuring-the-impact-of-github-copilot\/"
  },
  {
    "KPI Name":"AI Trust Score",
    "Benchmark":"AI trust score (e.g., from user surveys) should exceed 70% agreement that AI is helpful, accurate, and fair; this correlates with sustained feature usage.",
    "Definition":"Combined user ratings and satisfaction responses.",
    "Goal":"Measure user trust in AI through a combination of sentiment or confidence indicators.",
    "Category":"AI",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/kpmg.com\/xx\/en\/our-insights\/ai-and-technology\/trust-attitudes-and-use-of-ai.html"
  },
  {
    "KPI Name":"Latency Per AI Task",
    "Benchmark":"Latency per AI task (e.g., response generation) should remain under 500ms for UI-visible tasks; cited in Google AI, OpenAI, and HuggingFace inference latency documentation.",
    "Definition":"Time it takes for AI to return a usable result.",
    "Goal":"Track time it takes for AI features to process and return results to ensure responsiveness.",
    "Category":"AI",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/platform.openai.com\/docs\/guides\/latency-optimization"
  },
  {
    "KPI Name":"Smart Suggestion Utilization",
    "Benchmark":"At least 40% of smart suggestions (e.g., autocomplete, quick replies) should be accepted or clicked; benchmarked by Gmail Smart Compose, Notion AI, and Intercom",
    "Definition":"Frequency at which users accepts suggestions",
    "Goal":"Track how often users engage with smart suggestions to measure perceived helpfulness.",
    "Category":"AI",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/dl.acm.org\/doi\/10.1145\/3292500.3330723"
  },
  {
    "KPI Name":"AI Efficiency Gain Score",
    "Benchmark":"AI-assisted features should reduce task time or steps by at least 20% over manual processes; cited in IBM and McKinsey AI productivity impact studies.",
    "Definition":"Includes adoption, trust, satisfaction, override rate.",
    "Goal":"Measure productivity gains or time saved due to AI-enabled assistance.",
    "Category":"AI",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"Content Platform, Social Product",
    "More Info":"https:\/\/www.mckinsey.com\/capabilities\/mckinsey-digital\/our-insights\/the-economic-potential-of-generative-ai-the-next-productivity-frontier"
  },
  {
    "KPI Name":"North Star Experience Score ",
    "Benchmark":"North Star Experience Score should exceed 70\/100, based on internal scoring methods used by Intercom, Spotify, and Notion to reflect composite UX health.",
    "Definition":"3\u20135 metrics tied directly to a core user outcome.",
    "Goal":"Define a custom composite score representing the core experience you want to deliver.",
    "Category":"Composite",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"All",
    "More Info":"https:\/\/newsletter.pragmaticengineer.com\/p\/measuring-developer-productivity-bae"
  },
  {
    "KPI Name":"Journey Completion Velocity",
    "Benchmark":"Users should complete most core journeys in under 3 steps on average; benchmark aligned with UX simplification goals published by Nielsen Norman Group.",
    "Definition":"Speed to complete a critical end-to-end flow",
    "Goal":"Measure the speed and success with which users move through key stages in the product journey.",
    "Category":"Composite",
    "Metric Type":"Composite",
    "Design Stage":"Post-Launch",
    "User Journey Stage":"Advocacy",
    "B2B\/B2C":"B2C",
    "Monetization Suitability":"Pre\/Post-Monetization",
    "Applicable Project Types":"All",
    "More Info":"https:\/\/www.nngroup.com\/articles\/journey-mapping-101\/"
  }
]